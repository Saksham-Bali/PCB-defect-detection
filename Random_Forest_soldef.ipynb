{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ah2d_p-cgLd",
        "outputId": "e97620c0-7957-4da9-88ab-2bb3c7bd139a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
            "Classification Report (Random Forest + HOG + Augmentation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  exc_solder       0.71      0.67      0.69        33\n",
            "        good       0.55      0.73      0.63        66\n",
            "     no_good       0.68      0.68      0.68        47\n",
            " poor_solder       1.00      0.38      0.56        13\n",
            "       spike       1.00      0.27      0.42        15\n",
            "\n",
            "    accuracy                           0.64       174\n",
            "   macro avg       0.79      0.55      0.59       174\n",
            "weighted avg       0.69      0.64      0.63       174\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from skimage.feature import hog\n",
        "import albumentations as A\n",
        "\n",
        "IMG_SIZE = 128  # Smaller size for HOG efficiency\n",
        "DATA_FOLDER = '/content/drive/MyDrive/Colab Notebooks/Labeled'\n",
        "\n",
        "# --- Augmentation ---\n",
        "augment = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.Rotate(limit=15, p=0.3),\n",
        "])\n",
        "\n",
        "# --- Load and extract HOG features ---\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "def extract_hog_features(img):\n",
        "    gray = rgb2gray(img)  # Convert RGB to grayscale\n",
        "    features = hog(\n",
        "        gray,\n",
        "        orientations=9,\n",
        "        pixels_per_cell=(8, 8),\n",
        "        cells_per_block=(2, 2),\n",
        "        block_norm='L2-Hys',\n",
        "        visualize=False  # No need for visualization here\n",
        "    )\n",
        "    return features\n",
        "\n",
        "\n",
        "def load_images(data_folder):\n",
        "    X, y = [], []\n",
        "    for file in os.listdir(data_folder):\n",
        "        if file.endswith('.json'):\n",
        "            with open(os.path.join(data_folder, file)) as f:\n",
        "                label_data = json.load(f)\n",
        "            label = label_data['shapes'][0]['label']\n",
        "            image_path = os.path.join(data_folder, label_data['imagePath'])\n",
        "\n",
        "            if os.path.exists(image_path):\n",
        "                img = cv2.imread(image_path)\n",
        "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Original\n",
        "                X.append(extract_hog_features(img))\n",
        "                y.append(label)\n",
        "\n",
        "                # Augmented\n",
        "                img_aug = augment(image=img)['image']\n",
        "                X.append(extract_hog_features(img_aug))\n",
        "                y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load data\n",
        "X, y = load_images(DATA_FOLDER)\n",
        "\n",
        "# Label encoding\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "print(\"Classification Report (Random Forest + HOG + Augmentation):\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from skimage.feature import hog\n",
        "import albumentations as A\n",
        "\n",
        "IMG_SIZE = 224 # Smaller size for HOG efficiency\n",
        "DATA_FOLDER = '/content/drive/MyDrive/Colab Notebooks/Labeled'\n",
        "\n",
        "# --- Augmentation ---\n",
        "augment = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.Rotate(limit=15, p=0.3),\n",
        "])\n",
        "\n",
        "# --- Load and extract HOG features ---\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "def extract_hog_features(img):\n",
        "    gray = rgb2gray(img)  # Convert RGB to grayscale\n",
        "    features = hog(\n",
        "        gray,\n",
        "        orientations=9,\n",
        "        pixels_per_cell=(8, 8),\n",
        "        cells_per_block=(2, 2),\n",
        "        block_norm='L2-Hys',\n",
        "        visualize=False  # No need for visualization here\n",
        "    )\n",
        "    return features\n",
        "\n",
        "\n",
        "def load_images(data_folder):\n",
        "    X, y = [], []\n",
        "    for file in os.listdir(data_folder):\n",
        "        if file.endswith('.json'):\n",
        "            with open(os.path.join(data_folder, file)) as f:\n",
        "                label_data = json.load(f)\n",
        "            label = label_data['shapes'][0]['label']\n",
        "            image_path = os.path.join(data_folder, label_data['imagePath'])\n",
        "\n",
        "            if os.path.exists(image_path):\n",
        "                img = cv2.imread(image_path)\n",
        "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Original\n",
        "                X.append(extract_hog_features(img))\n",
        "                y.append(label)\n",
        "\n",
        "                # Augmented\n",
        "                img_aug = augment(image=img)['image']\n",
        "                X.append(extract_hog_features(img_aug))\n",
        "                y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load data\n",
        "X, y = load_images(DATA_FOLDER)\n",
        "\n",
        "# Label encoding\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Predict class labels\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report (Random Forest + HOG + Augmentation):\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "# Binarize true labels\n",
        "y_test_bin = label_binarize(y_test, classes=np.arange(len(le.classes_)))\n",
        "\n",
        "# Predict probabilities for mAP\n",
        "y_prob = best_rf.predict_proba(X_test)\n",
        "\n",
        "# Compute Average Precision (AP) for each class\n",
        "ap_per_class = []\n",
        "for i in range(len(le.classes_)):\n",
        "    ap = average_precision_score(y_test_bin[:, i], y_prob[:, i])\n",
        "    ap_per_class.append(ap)\n",
        "\n",
        "# Compute mean Average Precision (mAP)\n",
        "mean_ap = np.mean(ap_per_class)\n",
        "\n",
        "# Print AP per class and mAP\n",
        "print(\"\\nAverage Precision (per class):\")\n",
        "for label, ap in zip(le.classes_, ap_per_class):\n",
        "    print(f\"{label}: {ap:.4f}\")\n",
        "\n",
        "print(f\"\\nMean Average Precision (mAP): {mean_ap:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP6hAwh1ftPN",
        "outputId": "6d60c3eb-b150-49d6-b4d8-9fb5fc929c65"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
            "Classification Report (Random Forest + HOG + Augmentation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  exc_solder       0.71      0.52      0.60        33\n",
            "        good       0.52      0.76      0.62        66\n",
            "     no_good       0.58      0.55      0.57        47\n",
            " poor_solder       1.00      0.15      0.27        13\n",
            "       spike       1.00      0.47      0.64        15\n",
            "\n",
            "    accuracy                           0.59       174\n",
            "   macro avg       0.76      0.49      0.54       174\n",
            "weighted avg       0.65      0.59      0.57       174\n",
            "\n",
            "\n",
            "Average Precision (per class):\n",
            "exc_solder: 0.7974\n",
            "good: 0.7992\n",
            "no_good: 0.7463\n",
            "poor_solder: 0.3169\n",
            "spike: 0.8026\n",
            "\n",
            "Mean Average Precision (mAP): 0.6925\n"
          ]
        }
      ]
    }
  ]
}